{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"make_newmodelanddf.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMisw+NnNEHetDY+k9nr99"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A7krKbxw2FoI","executionInfo":{"status":"ok","timestamp":1650792187301,"user_tz":-540,"elapsed":51443,"user":{"displayName":"강민수","userId":"00225498109994330268"}},"outputId":"48e85985-aa23-4ede-c386-cc49a360132d"},"outputs":[{"output_type":"stream","name":"stdout","text":["openjdk version \"11.0.14.1\" 2022-02-08\n","OpenJDK Runtime Environment (build 11.0.14.1+1-Ubuntu-0ubuntu1.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.14.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n","sudo: update-alternativeAs: command not found\n","openjdk version \"11.0.14.1\" 2022-02-08\n","OpenJDK Runtime Environment (build 11.0.14.1+1-Ubuntu-0ubuntu1.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.14.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n","\n","WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n","\n","Mounted at /content/drive\n","Collecting pickle5\n","  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n","\u001b[K     |████████████████████████████████| 256 kB 4.9 MB/s \n","\u001b[?25hInstalling collected packages: pickle5\n","Successfully installed pickle5-0.0.12\n"]}],"source":["# java version 8로 변경\n","!java -version\n","!sudo update-alternativeAs --config java\n","!java -version\n","# 그래프에서 한글표현을 위해 폰트 설치\n","%config InlineBackend.figure_format = 'retina'\n","!apt -qq -y install fonts-nanum > /dev/null\n","\n","import matplotlib.font_manager as fm\n","fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n","font = fm.FontProperties(fname=fontpath, size=9)\n","\n","# 기본 글꼴 변경\n","import matplotlib as mpl\n","mpl.font_manager._rebuild()\n","mpl.pyplot.rc('font', family='NanumBarunGothic')\n","# tensorflow version을 2.x로 변경\n","try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","# 자동 reload\n","%load_ext autoreload\n","%autoreload 2\n","# 구글 드라이브와 연동\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!pip3 install pickle5"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import matplotlib.image as mpimg\n","!pip install pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.ml.recommendation import ALS, ALSModel\n","from tensorflow.keras.applications import MobileNetV2\n","from tqdm import tqdm\n","from scipy.spatial.distance import cosine\n","import pickle5\n","import joblib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BhlOLuyO4Ocr","executionInfo":{"status":"ok","timestamp":1650792442944,"user_tz":-540,"elapsed":52842,"user":{"displayName":"강민수","userId":"00225498109994330268"}},"outputId":"0567cb1b-059e-467d-8574-26cb85e56049"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 50.0 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=ab32c7e5f9b033e95efaff06ae990fda20d5d18cce57eceb07be6774cc367ba4\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"]}]},{"cell_type":"code","source":["hashtag_metadata=joblib.load('/content/drive/MyDrive/insta_crawling/preprocessed/dataframe/insta_df.pkl')"],"metadata":{"id":"F1CAHon85Nt3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# index 재정렬\n","pd.DataFrame.reset_index(hashtag_metadata, drop=True, inplace=True)"],"metadata":{"id":"KiHqk75e5vDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hashtag_metadata의 hashtags열에서 '#'으로 시작하는 해시태그만 저장\n","hashtag_metadata['해시태그'] = hashtag_metadata['해시태그'].apply(\n","    lambda hashtag_list: [h for h in hashtag_list if h.startswith('#')])\n","\n","# 2중 리스트를 flatten하게 만들어 모든 해시태그들을 담은 1차원 리스트 생성\n","all_hashtags = [hashtag for hashtags in hashtag_metadata['해시태그'] for hashtag in hashtags]\n","\n","# 중복 항목을 제거하기 위해 집합으로 변경하고 다시 리스트로 변경 후 정렬\n","all_hashtags = sorted(list(set(all_hashtags)))\n","\n","# hashtag 이름마다 번호를 매기기 위해 lookup 생성\n","hashtag_lookup = {hashtag: i for i, hashtag in enumerate(all_hashtags)}"],"metadata":{"id":"oneoj0FG5yrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hashtag_rec_data = []\n","for i in hashtag_metadata.index:\n","    hashtag_list = hashtag_metadata.loc[i, '해시태그']\n","    for hashtag in hashtag_list:\n","        hashtag_rec_data.append(\n","            {'image_id': i, # hashtag_metadata의 해당 index 번호를 image_id로 부여\n","             'hashtag_id': hashtag_lookup[hashtag], # hashtag_lookup에 있는 해당 해시태그 번호를 hashtag_id로 부여\n","             'rating': 1}\n","        )\n","hashtag_rec_data = pd.DataFrame(hashtag_rec_data)"],"metadata":{"id":"0xhtJXs35-iU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **dnn모델 만들기!!!!!**"],"metadata":{"id":"Pnkom_xi6GJq"}},{"cell_type":"code","source":["img_shape = (160, 160, 3)\n","\n","# 사전 학습된 MobileNetV2 모델을 base_model로 저장\n","base_model = MobileNetV2(input_shape=img_shape, include_top=False, weights='imagenet')\n","# ***dropout등 튜닝을 해도 될거같다!\n","# include_top: 네트워크의 최상단에 완전연결 레이어를 넣을지 여부\n","# 참고로 마지막 분류 계층 (\"상단\")은 피쳐 추출에 그리 유용하지 않으므로 include_top=False를 지정해 맨 위에 분류 계층을 제외\n","# weights: 'imagenet' (ImageNet에 대한 선행 학습)\n","\n","# tf.keras.layers.GlobalAveragePooling2D 레이어를 사용하여 피처를 이미지 당 하나의 1280 요소 벡터로 변환\n","global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n","\n","# base_model에 global_average_layer 쌓기\n","neural_network = tf.keras.Sequential([\n","  base_model,\n","  global_average_layer,\n","])\n","# joblib.dump(neural_network,'./model/mobilenetv2.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Go1OtuzG6BC0","executionInfo":{"status":"ok","timestamp":1650792689960,"user_tz":-540,"elapsed":2547,"user":{"displayName":"강민수","userId":"00225498109994330268"}},"outputId":"7ca76e84-2f30-4684-f8df-62c4ef212eb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","9420800/9406464 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["## **pic df 만들기!!!!!**"],"metadata":{"id":"LTGo8qgj6joH"}},{"cell_type":"code","source":["def prepare_image(img_path, height=160, width=160):\n","  # 신경망에 맞게 이미지를 다운 샘플링 및 스케일링\n","  img = tf.io.read_file(img_path) # 불러(읽어)오기\n","  img = tf.image.decode_jpeg(img) # [height, width, num_channels]인 3차원 배열을 반환\n","  img = tf.cast(img, tf.float32) # 정수형으로 바꾼경우 소수점을 버린다 boolean일때는 True면 1, False면 0을 출력\n","  img = (img/127.5) - 1\n","  img = tf.image.resize(img, (height, width))\n","  # 컬러 이미지의 차원에 맞게 회색조 이미지 형태변경\n","  if img.shape != (160, 160, 3):\n","    img = tf.concat([img, img, img], axis=2)\n","  return img\n","\n","def extract_features(image, neural_network):\n","  # input받은 이미지를 1280개의 deep feature들로 구성된 벡터로 반환\n","  image_np = image.numpy() # numpy형태로 변환\n","  images_np = np.expand_dims(image_np, axis=0) # 차원추가([]를 씌워준다)\n","  deep_features = neural_network.predict(images_np)[0]\n","  return deep_features"],"metadata":{"id":"bDkNaj7g8D_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지당 딥피쳐(deep_features)를 추출하고\n","# 이미지(pic), 검색키워드(hashtag),이미지 파일 이름(name), 피쳐(deep_features)를 보여주는 데이터프레임 생성\n","pics = []\n","\n","for i, row in tqdm(hashtag_metadata.iterrows()):\n","    name = row['이미지파일명']\n","    hashtag = row['검색키워드']\n","    img_path = f'/content/drive/MyDrive/insta_crawling/image/{hashtag}/{name}'\n","    try:\n","        img = prepare_image(img_path)\n","        deep_features = extract_features(img, neural_network)\n","        pics.append({'pic': img, \n","                     'hashtag': hashtag, # main_hashtag\n","                     'name': name, # image_local_name\n","                     'deep_features': deep_features})\n","    except Exception as e:\n","        error_type = type(e).__name__\n","        if error_type == \"NotFoundError\":\n","            pass\n","        else:\n","            print(e)\n","\n","pics = pd.DataFrame(pics)\n","pics.index = pics['name']\n","# joblib.dump(pics,'/content/drive/MyDrive/insta_crawling/Hashtag_Team16/modeling (1)/pics_0424_1.pkl')"],"metadata":{"id":"aIeTHwAz6WSy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **als모델 만들기!!!!!**"],"metadata":{"id":"mEUmblHf61bX"}},{"cell_type":"code","source":["hashtag_rec_data\n","#추천 데이터 양 확인"],"metadata":{"id":"snkw6TNc7DjV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기존 SparkSession을 가져 오거나 기존 SparkSession이없는 경우 local에 새 SparkSession을 작성\n","spark = SparkSession.builder.master('local').appName('all').getOrCreate()\n","from pyspark.sql import SparkSession\n","als = ALS(userCol='image_id',\n","          itemCol='hashtag_id',\n","          implicitPrefs=True, # implicit dataset의 경우 True\n","          alpha=40)\n","als.setSeed(0)\n","\n","hashtag_spark_df = spark.createDataFrame(hashtag_rec_data)\n","als_model = als.fit(hashtag_spark_df)\n","# als_model.write().overwrite().save('/content/drive/MyDrive/insta_crawling/Hashtag_Team16/modeling/als')"],"metadata":{"id":"k72CHO5k6ozG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **rec df,hashtags df 만들기!!!!!**"],"metadata":{"id":"As9vrJ5H7R0-"}},{"cell_type":"code","source":["# 각 이미지마다 10개의 해시태그 생성(=추천)\n","recs = als_model.recommendForAllUsers(numItems=50).toPandas()\n","\n","hashtag_index = list(all_hashtags)\n","\n","# hashtag_id로 hashtag 찾는 함수\n","def lookup_hashtag(hashtag_id):\n","    return hashtag_index[hashtag_id]\n","\n","# hashtag_id_scores에서 (hashtag_id, score)마다 hashtag_id의 hashtag 찾는 함수\n","def lookup_hashtag_recs(hashtag_id_scores):\n","    return [lookup_hashtag(hashtag_id) for (hashtag_id, score) in hashtag_id_scores]\n","    # recommendations열에서 hashtag_id로 hashtag를 찾아 recommended_hashtags열에 저장\n","recs['recommended_hashtags'] = recs['recommendations'].apply(lookup_hashtag_recs)\n","\n","recs.index = recs['image_id']\n","\n","# recs 데이터프레임을 기준으로 hashtag_metadata 데이터프레임과 병합\n","recs = recs.join(hashtag_metadata, how='left')[['recommendations',\n","                                                 'recommended_hashtags',\n","                                                 '해시태그',\n","                                                 '이미지파일명',\n","                                                 '검색키워드']]\n","                            \n","# recommendations열 삭제\n","recs.drop('recommendations', axis=1, inplace=True)\n","\n","# image_factors열 추가\n","image_factors = als_model.userFactors.toPandas()\n","image_factors.index = image_factors['id']\n","recs.join(image_factors);\n","\n","# recs 데이터프레임과 pics 데이터프레임을 image_local_name열 기준으로 병합\n","# 즉, deep_features열 추가\n","recs_deep = recs.join(pics, on='이미지파일명', how='inner')\n","\n","# dict에서 dataframe으로 변환\n","hashtags_df = pd.DataFrame.from_dict(hashtag_lookup, orient='index')\n","\n","hashtags_df = hashtags_df.reset_index()\n","hashtags_df.columns = ['hashtag', 'id']\n","hashtags_df.index = hashtags_df['id']\n","hashtags_df.drop('id', axis=1, inplace=True)\n","\n","img_features = als_model.userFactors.toPandas()\n","\n","hashtag_features = als_model.itemFactors.toPandas()\n","\n","# recs_deep 데이터프레임에서 특정 열만 사용\n","recs_deep_clean = recs_deep[['이미지파일명', '해시태그', 'deep_features']]\n","\n","img_features.index = img_features['id']\n","img_features.drop(['id'], axis=1, inplace=True)\n","\n","# recs_deep_clean 데이터프레임에 img_features 추가\n","recommender_df = recs_deep_clean.join(img_features, how='inner')\n","\n","# joblib.dump(recommender_df,'/content/drive/MyDrive/insta_crawling/Hashtag_Team16/modeling (1)/recommender_df_0424_1.pkl')\n","# joblib.dump(hashtags_df,'/content/drive/MyDrive/insta_crawling/Hashtag_Team16/modeling (1)/hashtags_df_0424_1.pkl')"],"metadata":{"id":"_v7F-xlh7QxH"},"execution_count":null,"outputs":[]}]}