{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22b5380",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:42:50.474466Z",
     "start_time": "2022-05-02T01:42:42.828765Z"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import Blueprint, request\n",
    "from werkzeug.utils import secure_filename\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from scipy.spatial.distance import cosine\n",
    "import joblib\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# 필요한 PyTorch 라이브러리 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from IPython.display import Image as display_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01197a",
   "metadata": {},
   "source": [
    "# 해시태그 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab5e0f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:42:52.649816Z",
     "start_time": "2022-05-02T01:42:50.477427Z"
    }
   },
   "outputs": [],
   "source": [
    "img_shape = (160, 160, 3)\n",
    "\n",
    "# 사전 학습된 MobileNetV2 모델을 base_model로 저장\n",
    "base_model = MobileNetV2(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "# ***dropout등 튜닝을 해도 될거같다!\n",
    "# include_top: 네트워크의 최상단에 완전연결 레이어를 넣을지 여부\n",
    "# 참고로 마지막 분류 계층 (\"상단\")은 피쳐 추출에 그리 유용하지 않으므로 include_top=False를 지정해 맨 위에 분류 계층을 제외\n",
    "# weights: 'imagenet' (ImageNet에 대한 선행 학습)\n",
    "\n",
    "# tf.keras.layers.GlobalAveragePooling2D 레이어를 사용하여 피처를 이미지 당 하나의 1280 요소 벡터로 변환\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "# base_model에 global_average_layer 쌓기\n",
    "neural_network = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "])\n",
    "# joblib.dump(neural_network,'./model/mobilenetv2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1010d52a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:06.973307Z",
     "start_time": "2022-05-02T01:42:52.651809Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local').appName('all').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea4771e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:14.464726Z",
     "start_time": "2022-05-02T01:43:06.978294Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######모델 불러오기 (dnn feature뽑아오기,als 해시태그 추천)\n",
    "# model_path='/content/drive/MyDrive/insta_crawling/Hashtag_Team16/modeling (1)/mobilenetv2.pkl'\n",
    "# neural_network = joblib.load(model_path)\n",
    "als_model = ALSModel.load('modeling/als')\n",
    "\n",
    "#######데이터 불러오기 (pics 이미지의 피처 데이터프레임,hashtags_df 모든해시태그, recommender_df 추천df)\n",
    "recommender_df=joblib.load('recommender_df_0424_1.pkl')\n",
    "hashtags_df=joblib.load('hashtags_df_0424_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a6b17a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:14.510394Z",
     "start_time": "2022-05-02T01:43:14.468717Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_image(img_path, height=160, width=160):\n",
    "    # 신경망에 맞게 이미지를 다운 샘플링 및 스케일링\n",
    "    img = tf.io.read_file(img_path) # 불러(읽어)오기\n",
    "    #img = tf.image.decode_jpeg(img) # [height, width, num_channels]인 3차원 배열을 반환\n",
    "    img = tf.image.decode_image(img)\n",
    "    img = tf.cast(img, tf.float32) # 정수형으로 바꾼경우 소수점을 버린다 boolean일때는 True면 1, False면 0을 출력\n",
    "    img = (img/127.5) - 1\n",
    "    img = tf.image.resize(img, (height, width))\n",
    "    # 컬러 이미지의 차원에 맞게 회색조 이미지 형태변경\n",
    "    if img.shape != (160, 160, 3):\n",
    "        img = tf.concat([img, img, img], axis=2)\n",
    "    return img\n",
    "\n",
    "def extract_features(image, neural_network):\n",
    "    # input받은 이미지를 1280개의 deep feature들로 구성된 벡터로 반환\n",
    "    image_np = image.numpy() # numpy형태로 변환\n",
    "    images_np = np.expand_dims(image_np, axis=0) # 차원추가([]를 씌워준다)\n",
    "    deep_features = neural_network.predict(images_np)[0]\n",
    "    return deep_features\n",
    "\n",
    "# 코사인 유사성에 기반한 K개의 최근접이웃을 찾는 함수 \n",
    "def find_neighbor_vectors(image_path, k=5, recommender_df=recommender_df):\n",
    "    # 비슷한 이미지에 대한 img_features(이미지 피쳐, 즉 사용자 벡터)를 찾는다.\n",
    "    prep_image = prepare_image(image_path)\n",
    "    pics = extract_features(prep_image, neural_network)\n",
    "    rdf = recommender_df.copy()\n",
    "    rdf['dist'] = rdf['deep_features'].apply(lambda x: cosine(x, pics))\n",
    "    rdf = rdf.sort_values(by='dist')\n",
    "    return rdf.head(k)\n",
    "  \n",
    "\n",
    "def generate_hashtags(image_path):\n",
    "    fnv = find_neighbor_vectors(image_path, k=5, recommender_df=recommender_df)\n",
    "    # 코사인 유사성에 기반하여 5개의 사용자 벡터의 평균을 구한다.\n",
    "    features = []\n",
    "    for item in fnv.features.values:\n",
    "        features.append(item)\n",
    "\n",
    "    avg_features = np.mean(np.asarray(features), axis=0)\n",
    "    \n",
    "    hashtag_features = als_model.itemFactors.toPandas()\n",
    "\n",
    "    # 앞서 구한 이미지(사용자) 피쳐의 평균, 즉 avg_features을 hashtag_features와 dot product하여 새로운 dot_product열 생성\n",
    "    hashtag_features['dot_product'] = hashtag_features['features'].apply(lambda x: np.asarray(x).dot(avg_features))\n",
    "    \n",
    "    # 가장 높은 dot product를 가진 해시태그 상위 10개 추출\n",
    "    final_recs = hashtag_features.sort_values(by='dot_product', ascending=False).head(50)\n",
    "\n",
    "    # hastag_id로 hashtag 찾아서 output에 저장\n",
    "    output = []\n",
    "    for hashtag_id in final_recs.id.values:\n",
    "        output.append(hashtags_df.iloc[hashtag_id]['hashtag'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4338c9",
   "metadata": {},
   "source": [
    "# 이미지 스타일 전이 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2fd6e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:14.749778Z",
     "start_time": "2022-05-02T01:43:14.515379Z"
    }
   },
   "outputs": [],
   "source": [
    "# 인코더(Encoder) 정의\n",
    "vgg = nn.Sequential(\n",
    "    nn.Conv2d(3, 3, (1, 1)),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(3, 64, (3, 3)),\n",
    "    nn.ReLU(), # relu1-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 64, (3, 3)),\n",
    "    nn.ReLU(), # relu1-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 128, (3, 3)),\n",
    "    nn.ReLU(), # relu2-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 128, (3, 3)),\n",
    "    nn.ReLU(), # relu2-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 256, (3, 3)),\n",
    "    nn.ReLU(), # relu3-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(), # relu3-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(), # relu3-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(), # relu3-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 512, (3, 3)),\n",
    "    nn.ReLU(), # relu4-1, this is the last layer used\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(), # relu4-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(), # relu4-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(), # relu4-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(), # relu5-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(), # relu5-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(), # relu5-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU() # relu5-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa9cda9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:14.825044Z",
     "start_time": "2022-05-02T01:43:14.752779Z"
    }
   },
   "outputs": [],
   "source": [
    "# 디코더(Decoder) 정의\n",
    "decoder = nn.Sequential(\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 256, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 128, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 128, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 64, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 64, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 3, (3, 3)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb82260e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:14.975605Z",
     "start_time": "2022-05-02T01:43:14.827004Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder.eval()\n",
    "vgg.eval()\n",
    "\n",
    "vgg_path = './vgg_normalised.pth'\n",
    "decoder_path = './decoder.pth'\n",
    "\n",
    "decoder.load_state_dict(torch.load(decoder_path))\n",
    "vgg.load_state_dict(torch.load(vgg_path))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "vgg = nn.Sequential(*list(vgg.children())[:31]) # ReLU4_1까지만 사용하기 위해 뒤쪽은 자름."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "841bb307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:15.005524Z",
     "start_time": "2022-05-02T01:43:14.982586Z"
    }
   },
   "outputs": [],
   "source": [
    "# 피처맵에 대해 평균과 표준편차를 구해서 리턴하는 함수\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    size = feat.size()\n",
    "    assert (len(size) == 4)\n",
    "    N, C = size[:2]\n",
    "    feat_var = feat.view(N, C, -1).var(dim=2) + eps #하나의 벡터로 만든 뒤, variance를 구해주고, 0이 되지 않도록 작은 값을 더해줌\n",
    "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
    "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
    "    return feat_mean, feat_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fac0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:15.035444Z",
     "start_time": "2022-05-02T01:43:15.014501Z"
    }
   },
   "outputs": [],
   "source": [
    "def adaptive_instance_normalization(content_feat, style_feat):\n",
    "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
    "    size = content_feat.size()\n",
    "    style_mean, style_std = calc_mean_std(style_feat)\n",
    "    content_mean, content_std = calc_mean_std(content_feat)\n",
    "\n",
    "    # 평균(mean)과 표준편차(std)를 이용하여 정규화 수행\n",
    "    normalized_feat = (content_feat - content_mean.expand(size)) / content_std.expand(size)\n",
    "    # 정규화 이후에 style feature의 statistics를 가지도록 설정\n",
    "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ad984f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:15.050919Z",
     "start_time": "2022-05-02T01:43:15.038437Z"
    }
   },
   "outputs": [],
   "source": [
    "def style_transfer(vgg, decoder, content, style, alpha=1.0):\n",
    "    assert (0.0 <= alpha <= 1.0)\n",
    "    content_f = vgg(content)\n",
    "    style_f = vgg(style)\n",
    "    feat = adaptive_instance_normalization(content_f, style_f)\n",
    "    feat = feat * alpha + content_f * (1 - alpha)\n",
    "    return decoder(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6d1529e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:15.080841Z",
     "start_time": "2022-05-02T01:43:15.054908Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_transform(size=512):\n",
    "    transform_list = []\n",
    "    if size != 0:\n",
    "        transform_list.append(transforms.Resize(size))\n",
    "    transform_list.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(transform_list)\n",
    "    return transform\n",
    "\n",
    "content_tf = test_transform()\n",
    "style_tf = test_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff97a43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T01:43:15.096797Z",
     "start_time": "2022-05-02T01:43:15.083829Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9432447",
   "metadata": {},
   "source": [
    "# 서버 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d7290",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-02T01:42:42.865Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses (0.0.0.0)\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.30.1.16:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_image/43d6f3c6-c9b9-11ec-9e22-c03c596ba129jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\hashtaig\\lib\\site-packages\\pyspark\\sql\\context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n",
      "C:\\Users\\User\\anaconda3\\envs\\hashtaig\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n",
      "127.0.0.1 - - [02/May/2022 10:43:41] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_image/4f2e026e-c9bb-11ec-90ea-c03c596ba129jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/May/2022 10:58:14] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask import Blueprint, request\n",
    "from werkzeug.utils import secure_filename\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "# HTTP POST방식으로 전송된 이미지를 저장\n",
    "@app.route('/', methods=['POST'])\n",
    "def input_image():\n",
    "    f = request.files['file']\n",
    "    secure_name = secure_filename(f.filename)\n",
    "    unique_name = str(uuid.uuid1())\n",
    "    save_image_path = 'save_image/' + unique_name + secure_filename(f.filename)\n",
    "    save_style_transfer_image_path = 'save_style_transfer_image/'+ unique_name + secure_filename(f.filename) + '.jpg'\n",
    "    print(save_image_path)\n",
    "    f.save(save_image_path)\n",
    "    recommended_hashtags = generate_hashtags(save_image_path) #원래는 이미지 확장자 생각해서 적용해야함.\n",
    "    \n",
    "    content = content_tf(Image.open(save_image_path))\n",
    "    style1 = style_tf(Image.open(str('E:/googledrive/aivle/big_proj/ML_API/style_image/style2_drawing/pic2.jfif')))\n",
    "\n",
    "    style1 = style1.to(device).unsqueeze(0)\n",
    "    content = content.to(device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output1 = style_transfer(vgg, decoder, content, style1, alpha=1.0)\n",
    "    output1 = output1.cpu()\n",
    "\n",
    "    save_image(output1, save_style_transfer_image_path)\n",
    "    \n",
    "    img = cv2.imread(save_style_transfer_image_path)\n",
    "    jpg_img = cv2.imencode('.jpg', img)\n",
    "    b64_string = base64.b64encode(jpg_img[1]).decode('utf-8')\n",
    "    \n",
    "    hashtags_dict = {'hashtags':recommended_hashtags,\n",
    "                    'img': b64_string}\n",
    "    hashtags_json = json.dumps(hashtags_dict, sort_keys=True)\n",
    "    return hashtags_json\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c39f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165.81px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
